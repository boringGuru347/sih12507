# Kolam Classifier - Binary Classification (Sikku vs Non-Sikku)"# Kolam Design Classifier ğŸ¨



A deep learning project for classifying traditional South Indian Kolam patterns into Sikku and Non-Sikku categories using PyTorch and computer vision techniques.A deep learning project that classifies different types of Kolam designs using a few-shot learning approach with EfficientNet-B0 backbone.



## ğŸ¯ Project Overview## ğŸ¯ Project Overview



This project implements a binary classifier to distinguish between two types of Kolam designs:This project implements a few-shot learning classifier for Kolam designs using:

- **Sikku Kolam**: Continuous line patterns- **Prototypical Networks** for few-shot learning

- **Non-Sikku Kolam**: Discontinuous line patterns- **EfficientNet-B0** as the feature extractor backbone

- **HuggingFace Datasets** to load the `ayshthkr/kolam_dataset`

## ğŸš€ Key Features- **PyTorch** for deep learning implementation



- **High Accuracy**: 99.8% accuracy on test dataset## ğŸ“ Project Structure

- **Robust Preprocessing**: 9-step OpenCV preprocessing pipeline

- **Data Augmentation**: Comprehensive augmentation for better generalization```

- **Production Ready**: Complete training and testing pipelineKolam Classifier/

- **Balanced Performance**: Excellent performance on both classes despite class imbalanceâ”œâ”€â”€ few_shot_kolam_classifier.py    # Few-shot classifier implementation

â”œâ”€â”€ few_shot_kolam_classifier.pth   # Trained model weights

## ğŸ“Š Performance Metricsâ”œâ”€â”€ kolam_classifier_wrapper.py     # Wrapper class for easy usage

â”œâ”€â”€ inference.py                    # Inference script for predictions

- **Overall Accuracy**: 99.8% (629/630 correct predictions)â”œâ”€â”€ requirements_fewshot.txt        # Python dependencies

- **Non-Sikku Class**: 93.8% recall, 100% precisionâ””â”€â”€ README.md                      # This file

- **Sikku Class**: 100% recall, 99.8% precision```

- **F1-Score**: 98.3% overall

## ğŸ”§ Installation & Setup

## ğŸ› ï¸ Technical Stack

### Prerequisites

- **Framework**: PyTorch- Python 3.9 or later

- **Architecture**: EfficientNet-B0 backbone with custom classifier- CUDA-compatible GPU (optional but recommended)

- **Preprocessing**: OpenCV-based image enhancement

- **Data Augmentation**: Rotations, flips, perspective transforms, color jitter### Install Dependencies

- **Training**: Early stopping, train/validation split (80/20)```bash

pip install -r requirements_fewshot.txt

## ğŸ“ Project Structure```



```## ğŸš€ Usage

Kolam Classifier/

â”œâ”€â”€ optimized_kolam_trainer.py    # Main training script### 1. Using the Pre-trained Model

â”œâ”€â”€ test_binary_classifier.py     # Testing and evaluation script

â”œâ”€â”€ preprocessing.py               # Image preprocessing pipelineThe project includes a pre-trained few-shot Kolam classifier. Use the wrapper class for easy predictions:

â”œâ”€â”€ binary_training_curves.png    # Training visualization

â”œâ”€â”€ kolam_dataset/                 # Dataset folder```python

â”‚   â”œâ”€â”€ Sikku/                     # Sikku kolam images (664 images)from kolam_classifier_wrapper import KolamClassifier

â”‚   â””â”€â”€ Non - Sikku/               # Non-Sikku kolam images (81 images)from PIL import Image

â””â”€â”€ .gitignore                     # Git ignore file

```# Initialize classifier

classifier = KolamClassifier()

## ğŸƒâ€â™‚ï¸ Quick Start

# Load and predict on an image

### Prerequisitesimage = Image.open('your_kolam_image.jpg')

```bashresult = classifier.predict_kolam_type(image)

pip install torch torchvision opencv-python pillow matplotlib seaborn scikit-learn numpy

```print(f"Predicted class: {result['predicted_class']}")

print(f"Confidence: {result['confidence']:.2%}")

### Training the Model```

```bash

python optimized_kolam_trainer.py### 2. Using the Inference Script

```

Run the inference script directly:

### Testing the Model```bash

```bashpython inference.py

python test_binary_classifier.py```

```

This will load the trained model and make predictions on sample images.

## ğŸ“ˆ Training Process

### 3. Training a New Model

1. **Data Loading**: Loads images from Sikku and Non-Sikku folders

2. **Preprocessing**: Applies 9-step OpenCV enhancement pipelineIf you want to train your own model, use the few-shot classifier:

3. **Augmentation**: Random rotations, flips, perspective transforms```bash

4. **Training**: EfficientNet-B0 with custom classifier headpython few_shot_kolam_classifier.py

5. **Validation**: 80/20 train/validation split```

6. **Early Stopping**: Stops training when validation accuracy plateaus

## ğŸ“Š Model Architecture

## ğŸ”¬ Preprocessing Pipeline

- **Architecture**: Prototypical Networks (Few-shot Learning)

The preprocessing module applies the following steps:- **Backbone**: EfficientNet-B0 (pretrained on ImageNet)

1. Noise reduction (Gaussian blur)- **Feature Dimension**: 1280 â†’ 256 (with projection layer)

2. Histogram equalization (CLAHE)- **Input Size**: 224Ã—224 pixels

3. Gaussian blur- **Output Classes**: 8 Kolam categories

4. Edge enhancement- **Learning Approach**: Few-shot learning with prototypical networks

5. Morphological operations

6. Contrast enhancement## ğŸ”„ Data Processing Pipeline

7. Additional noise reduction

8. Final contrast adjustment### Few-shot Learning Setup:

9. Brightness normalization- **Support Set**: Small number of examples per class for prototypes

- **Query Set**: Test examples for classification

## ğŸ“Š Dataset Information- **Episode-based Training**: Simulates few-shot scenarios during training



- **Total Images**: 745### Preprocessing:

- **Sikku Images**: 664 (89%)- Resize to 224Ã—224 pixels

- **Non-Sikku Images**: 81 (11%)- Normalize with ImageNet mean/std values

- **Image Formats**: JPG, JPEG, PNG- Data augmentation during training (horizontal flip, rotation, color jitter)

- **Resolution**: Variable (preprocessed to 224x224)

## ğŸ“ˆ Training Process

## ğŸ¯ Model Architecture

The few-shot learning pipeline includes:

- **Backbone**: EfficientNet-B0 (pretrained on ImageNet)1. **Dataset Loading**: Load from HuggingFace `ayshthkr/kolam_dataset`

- **Feature Extractor**: 1280 â†’ 512 â†’ 256 â†’ 128 features2. **Episode Creation**: Generate training episodes with support/query sets

- **Classifier**: 128 â†’ 2 classes (Sikku/Non-Sikku)3. **Prototype Learning**: Learn class prototypes from support examples

- **Activation**: ReLU with Dropout (0.3)4. **Distance-based Classification**: Classify queries based on prototype distances

- **Loss Function**: CrossEntropyLoss5. **Model Saving**: Save trained prototypical network weights

- **Optimizer**: Adam with learning rate scheduling

## ğŸ“Š Evaluation Metrics

## ğŸ“‹ Results Summary

The few-shot model is evaluated using:

### Confusion Matrix- **Episode-based Accuracy**: Performance on few-shot episodes

```- **Confidence Scores**: Probability distributions for predictions

             Predicted- **Class-wise Performance**: Individual class prediction accuracy

Actual    Non-Sikku  Sikku

Non-Sikku        15      1## ğŸ’¾ Model Loading

Sikku             0    614

```The pre-trained model (`few_shot_kolam_classifier.pth`) includes:

- Prototypical network state dictionary

### Class-wise Performance- Class names mapping

- **Non-Sikku**: 93.8% accuracy (15/16 correct)- Feature extraction backbone weights

- **Sikku**: 100% accuracy (614/614 correct)

Load easily using the wrapper class for immediate inference.

## ğŸ”§ Configuration

## ğŸ” Features

Key training parameters:

- **Batch Size**: 16### Few-Shot Classifier (`few_shot_kolam_classifier.py`)

- **Learning Rate**: 0.001- âœ… Prototypical Networks implementation

- **Max Epochs**: 100- âœ… EfficientNet-B0 feature extraction

- **Early Stopping Patience**: 5- âœ… Episode-based training

- **Validation Split**: 20%- âœ… Few-shot learning capabilities

- **Data Augmentation**: Enabled for training- âœ… Model saving and loading



## ğŸ“ Usage Examples### Classifier Wrapper (`kolam_classifier_wrapper.py`)

- âœ… Easy-to-use interface for predictions

### Training a New Model- âœ… Confidence score calculation

```python- âœ… Class name mapping

from optimized_kolam_trainer import train_optimized_model- âœ… Error handling and validation

train_optimized_model()

```### Inference Script (`inference.py`)

- âœ… Load pre-trained model

### Testing Trained Model- âœ… Predict on sample images

```python- âœ… Confidence scores and probabilities

from test_binary_classifier import test_binary_classifier- âœ… Visual results display

test_binary_classifier()

```## ğŸ¨ Kolam Categories



### Using PreprocessingThe model classifies 8 different types of Kolams:

```python- **geometric**: Geometric patterns

from preprocessing import KolamPreprocessor- **butterfly**: Butterfly-shaped designs

preprocessor = KolamPreprocessor()- **pulli**: Dot-based kolams

processed_image = preprocessor.preprocess_image(image_array)- **flower**: Floral patterns

```- **naga**: Snake-inspired designs

- **sikku**: Line-based interlaced patterns

## ğŸ¤ Contributing- **kamal**: Lotus-inspired designs

- **traditional**: Classical traditional patterns

1. Fork the repository

2. Create a feature branch## ğŸ”§ Customization

3. Commit your changes

4. Push to the branch### Model Parameters

5. Create a Pull RequestYou can modify parameters in `few_shot_kolam_classifier.py`:

- `feature_dim`: Feature dimension for embeddings

## ğŸ“„ License- `backbone`: Feature extraction backbone model

- Episode configuration for training

This project is open source and available under the MIT License.

### Wrapper Configuration

## ğŸ™ AcknowledgmentsModify `kolam_classifier_wrapper.py` for:

- Custom class mappings

- Traditional Kolam art form and cultural heritage- Confidence thresholds

- OpenCV and PyTorch communities- Input preprocessing options

- EfficientNet architecture by Google Research

## ğŸ“‹ System Requirements

## ğŸ“ Contact

- **RAM**: 8GB minimum, 16GB recommended

For questions or collaborations, please open an issue in this repository.- **GPU**: CUDA-compatible GPU with 4GB+ VRAM (optional)

- **Storage**: 2GB free space for dataset and models

---

## ğŸ› Troubleshooting

**Note**: This project is designed for educational and research purposes in computer vision and cultural pattern recognition.
### Common Issues:
1. **Model loading error**: Ensure `few_shot_kolam_classifier.pth` exists
2. **Import errors**: Install dependencies with `pip install -r requirements_fewshot.txt`
3. **CUDA issues**: Model automatically uses CPU if CUDA unavailable
4. **Image format errors**: Ensure images are in supported formats (JPG, PNG)

### Performance Tips:
- Use GPU for faster inference
- PIL Image objects work best for predictions
- Ensure images are properly formatted before prediction

## ğŸ“œ License

This project is open source and available under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Support

If you encounter any issues or have questions, please create an issue in the repository.

---

**Happy Kolam Classification! ğŸ¨âœ¨**" 
